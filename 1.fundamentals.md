# Seven Testing Principles

## Testing shows the presence of defects 
-Testing shows that defects are present in the system, it does not prove their absence.  If 
no defects are found, its not proof that they don't exist. 

## Exhaustive Testing is impossible
-Testing everything, which means all possible combination of inputs and preconditions 
is not feasible. As an alternative, risk analysis and priorities should be focused on 
testing efforts

## Early testing
-Finding defects earlier in the development cycle will save an exponential amount of time and $$$

## Defect Clustering
-It is possible that more defects are clustered in smaller modules compared to being distributed
among bigger and other modules.     

## Pesticide Paradox
-If the same tests are repeated over and over again, eventually the same set of test cases
will no longer help find new defects.   To overcome this "pesticide paradox" test cases need to 
be regularly reviewed and revised. 

## Testing Context dependent
-testing is done differently in different context.  Two different software are testing with
different strategy. 

## Absence of error fallacy
-Meeting the requirement is equally important.  Finding and fixing defect doesn't help if the system built doesn't fulfill the users' need and expectation.  



# Test process

## Test Planning
-Determines the scope and risks & identifies the objective of testing
-Determines the overall approach of testing
-Scheduling test activities, Assigning Resources for said activities
-defining the amount, detail, template for documentation
-selecting metrics for monitoring and controlling
-defining entry and exit criteria
-deciding about automation


## Test Monitoring & Control

### Test Monitoring
-the process of measuring progress on the project

### Test Metrics
-These certain set of formulae which calculates any dimensions(test, defects, coverage) of testing

Test execution rate:   [# of test cases executed/# of test cases planned] x 100

### Test Control
-Involves taking necessary actions to meet the objerctives of the test plan


## Test Analysis
-Analyzing the Test Basis
-Evaluating the test basis and test items to identify defects of various types, such as ambiguities, omissions, inconsistencies, inaccuracies etc
-defining and prioritizing test conditions for each feature basedon analysis of the test basis
-considering functional, non functional and structural characteristics, other business and technical factors and levels of risk


## Test Design
-Designing and prioritizing test cases
-identifying necessary test data to support the test conditions and test cases
-designing the test environment and indentifying required infrastructure & tools
-creating bi-directional traceability between test basis and tests cases


## Test Implementation
-Developing and prioritizing test procedures & potentially creating automated test scripts
-creating test suites from the test procedures and (if any) automated test scripts
-arranging the test suites within a test execution schedule in a way that results in efficient test execution
-buidling the test environment(test harnesses, service virtualization, simulators etc) and verifying that 
everything needed has been setup correctly
-preparing test data & ensuring it is properly loaded in the test environment
-verifying and updating bi-directional traceability between the test basis, test conditions, test cases
test prodcedures and test suites


## Test Execution
-recording the IDs and versions of the test items or test object, test tools and testware
-executing tests either manually or by using test execution tools
-comparing actual results with expected results
-analyzing anomalies to establish their likely causes (e.g failures may occur due to defects in code
but false positives also may occur)
-reporting defects based on the failures observed
-logging the outcome of test execution (e.g..pass, fail, blocked)
-repeating test activities either as a result of action taken for an anomaly or as part of the planned testing
(e.g execution of a corrected test, confirmation testing and/or regression testing)


## Test Completion
-checking wheather all defect reports are closed, entering change requests or product backlog items for
any defects that remain unresolved at the end of test execution
-creating a test summary report to be communicated to stakeholders
-finalizing and archiving the test environment, test data, test infrastructure and other testware for later resuse


# The phsycology of Testing
-be nice if you find errors.  People tend to be proud of their work and will take things personally. 
This can create tension between the devs and QA.   Don't be an ass.  




